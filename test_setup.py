#!/usr/bin/env python3
"""
Simple test script to verify RAG chatbot functionality
"""

import sys
import os
from pathlib import Path

# Add backend to path
sys.path.append(str(Path(__file__).parent / "backend"))

def test_imports():
    """Test if all required modules can be imported."""
    print("ğŸ” Testing imports...")
    
    try:
        import chromadb
        print("âœ… ChromaDB imported successfully")
    except ImportError as e:
        print(f"âŒ ChromaDB import failed: {e}")
        return False
    
    try:
        from sentence_transformers import SentenceTransformer
        print("âœ… SentenceTransformers imported successfully")
    except ImportError as e:
        print(f"âŒ SentenceTransformers import failed: {e}")
        return False
    
    try:
        import fastapi
        print("âœ… FastAPI imported successfully")
    except ImportError as e:
        print(f"âŒ FastAPI import failed: {e}")
        return False
    
    try:
        import streamlit
        print("âœ… Streamlit imported successfully")
    except ImportError as e:
        print(f"âŒ Streamlit import failed: {e}")
        return False
    
    return True

def test_document_processor():
    """Test document processor functionality."""
    print("\nğŸ“„ Testing document processor...")
    
    try:
        from backend.document_processor import DocumentProcessor
        
        # Initialize processor
        processor = DocumentProcessor()
        print("âœ… Document processor initialized")
        
        # Check if documents exist
        docs_path = Path("./data/sample_docs")
        pdf_files = list(docs_path.glob("*.pdf"))
        print(f"ğŸ“ Found {len(pdf_files)} PDF files")
        
        if pdf_files:
            print("âœ… Documents ready for processing")
            
            # Test processing one document
            print("ğŸ”„ Processing documents...")
            processor.process_documents(str(docs_path))
            print("âœ… Documents processed successfully!")
            
            # Test search
            print("ğŸ” Testing search...")
            results = processor.search_similar_chunks("test query", n_results=3)
            if results.get("documents") and results["documents"][0]:
                print(f"âœ… Search working! Found {len(results['documents'][0])} results")
            else:
                print("âš ï¸ Search returned no results")
        else:
            print("âŒ No PDF files found in data/sample_docs/")
            
    except Exception as e:
        print(f"âŒ Document processor test failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

def test_api_components():
    """Test API components."""
    print("\nğŸ”— Testing API components...")
    
    try:
        from backend.main import app
        print("âœ… FastAPI app created successfully")
        
        from backend.llm_interface import LLMInterface
        llm = LLMInterface()  # Without model
        print("âœ… LLM interface initialized (fallback mode)")
        
    except Exception as e:
        print(f"âŒ API components test failed: {e}")
        return False
    
    return True

def main():
    """Run all tests."""
    print("ğŸš€ Starting RAG Chatbot Tests...\n")
    
    # Test imports
    if not test_imports():
        print("\nâŒ Import tests failed. Please install missing packages.")
        return
    
    # Test document processor
    if not test_document_processor():
        print("\nâŒ Document processor tests failed.")
        return
    
    # Test API components
    if not test_api_components():
        print("\nâŒ API component tests failed.")
        return
    
    print("\nğŸ‰ All tests passed!")
    print("\nğŸ“ Next steps:")
    print("1. Start the backend: python backend/main.py")
    print("2. Start the frontend: streamlit run frontend/streamlit_app.py")
    print("3. Open http://localhost:8501 in your browser")
    print("\nğŸ’¡ Note: The system will work without a local LLM model,")
    print("   but responses will be basic. For better results:")
    print("   - Download a GGUF model to the models/ directory")
    print("   - Install llama-cpp-python with proper build tools")

if __name__ == "__main__":
    main()